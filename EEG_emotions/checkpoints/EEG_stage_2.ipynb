{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем данные и визуализируем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"TkAgg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "import keras\n",
    "\n",
    "from os import walk\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "mne.set_log_level('WARNING')\n",
    "data_path = \"./data/resting_state/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatches(arr, batch_size=50, axis=0):\n",
    "    n = arr.shape[axis] // batch_size\n",
    "    return np.array_split(arr, n, axis=axis)\n",
    "\n",
    "def prepareData(file_path):\n",
    "    raw = np.array(mne.io.read_raw_brainvision(file_path, preload=True).to_data_frame())\n",
    "    batches = np.array(getBatches(raw))\n",
    "    del raw\n",
    "    \n",
    "    return batches\n",
    "#     flat = batches.reshape(-1, batches.shape[1] * batches.shape[2])\n",
    "#     del batches\n",
    "    \n",
    "#     return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12057, 50, 61)\n",
      "(24658, 50, 61)\n",
      "(31044, 50, 61)\n",
      "(43123, 50, 61)\n",
      "(55207, 50, 61)\n",
      "(61639, 50, 61)\n",
      "(73696, 50, 61)\n",
      "(85896, 50, 61)\n",
      "(97987, 50, 61)\n",
      "(110042, 50, 61)\n",
      "(122174, 50, 61)\n",
      "(134933, 50, 61)\n",
      "(147012, 50, 61)\n",
      "(159690, 50, 61)\n",
      "(171758, 50, 61)\n",
      "(177798, 50, 61)\n",
      "(189872, 50, 61)\n",
      "(202926, 50, 61)\n",
      "(215004, 50, 61)\n",
      "(227509, 50, 61)\n",
      "(233564, 50, 61)\n",
      "(245606, 50, 61)\n",
      "(257702, 50, 61)\n",
      "(270167, 50, 61)\n",
      "(282311, 50, 61)\n",
      "(294410, 50, 61)\n",
      "(307285, 50, 61)\n",
      "(319349, 50, 61)\n",
      "(331500, 50, 61)\n",
      "(343576, 50, 61)\n",
      "(355908, 50, 61)\n",
      "(368220, 50, 61)\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "\n",
    "for elem in walk(data_path):\n",
    "    for file in elem[-1]:\n",
    "        if file[-4:] == \"vhdr\":\n",
    "            files.append(file)\n",
    "\n",
    "data = np.ndarray(shape=(0, 50, 61))\n",
    "for file in files:\n",
    "    file_name = data_path + file\n",
    "    \n",
    "    batches =  prepareData(file_name)\n",
    "    data = np.concatenate((data, batches), axis=0)\n",
    "    print(data.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257754, 50, 61) (110466, 50, 61)\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.permutation(data.shape[0])\n",
    "training_ids, test_ids = indices[:(data.shape[0] // 10) * 7], indices[(data.shape[0] // 10) * 7:]\n",
    "X_train, X_test = data[training_ids,:,:], data[test_ids,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть, состоящую из encoder'а и decoder'а, в каждом из которых сделаем по одному полносвязному скрытому слою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "def create_dense_ae():\n",
    "    encoding_dim = 1000\n",
    "\n",
    "    # Энкодер\n",
    "    input_img = Input(shape=(50, 61))\n",
    "    flat_img = Flatten()(input_img)\n",
    "    encoded = Dense(encoding_dim, activation=\"elu\")(flat_img)\n",
    "\n",
    "    # Декодер\n",
    "    input_encoded = Input(shape=(encoding_dim,))\n",
    "    flat_decoded = Dense(50*61, activation=\"elu\")(input_encoded)\n",
    "    decoded = Reshape((50, 61))(flat_decoded)\n",
    "\n",
    "    # Модели, в конструктор первым аргументом передаются входные слои, а вторым выходные слои\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 50, 61)            0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 1000)              3051000   \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 50, 61)            3053050   \n",
      "=================================================================\n",
      "Total params: 6,104,050\n",
      "Trainable params: 6,104,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder, autoencoder = create_dense_ae()\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 257754 samples, validate on 110466 samples\n",
      "Epoch 1/50\n",
      "257754/257754 [==============================] - 126s 490us/step - loss: 172301113.8758 - val_loss: 160282988.2706\n",
      "Epoch 2/50\n",
      "257754/257754 [==============================] - 126s 490us/step - loss: 154113621.3583 - val_loss: 152664776.4952\n",
      "Epoch 3/50\n",
      "257754/257754 [==============================] - 126s 490us/step - loss: 146879536.3751 - val_loss: 144920509.2932\n",
      "Epoch 4/50\n",
      "257754/257754 [==============================] - 126s 488us/step - loss: 144563120.9825 - val_loss: 144801666.0237\n",
      "Epoch 5/50\n",
      "257754/257754 [==============================] - 126s 488us/step - loss: 114939322.5141 - val_loss: 109878775.8020\n",
      "Epoch 6/50\n",
      "257754/257754 [==============================] - 126s 489us/step - loss: 109552836.1450 - val_loss: 109651969.4344\n",
      "Epoch 7/50\n",
      "257754/257754 [==============================] - 126s 487us/step - loss: 109295297.5332 - val_loss: 109475948.8216\n",
      "Epoch 8/50\n",
      "257754/257754 [==============================] - 126s 489us/step - loss: 109104536.8541 - val_loss: 109324911.4897\n",
      "Epoch 9/50\n",
      "257754/257754 [==============================] - 126s 487us/step - loss: 107598855.1915 - val_loss: 102184229.1534\n",
      "Epoch 10/50\n",
      "257754/257754 [==============================] - 126s 487us/step - loss: 101924468.7973 - val_loss: 102141413.1830\n",
      "Epoch 11/50\n",
      "257754/257754 [==============================] - 126s 488us/step - loss: 101845246.6765 - val_loss: 102029823.2113\n",
      "Epoch 12/50\n",
      "257754/257754 [==============================] - 126s 487us/step - loss: 91293067.6082 - val_loss: 74270556.2867\n",
      "Epoch 13/50\n",
      "257754/257754 [==============================] - 126s 488us/step - loss: 72029416.9677 - val_loss: 67211658.3107\n",
      "Epoch 14/50\n",
      "257754/257754 [==============================] - 128s 495us/step - loss: 67011796.6762 - val_loss: 67154336.1389\n",
      "Epoch 15/50\n",
      "257754/257754 [==============================] - 128s 495us/step - loss: 66921840.8582 - val_loss: 67026107.1871\n",
      "Epoch 16/50\n",
      "257754/257754 [==============================] - 127s 494us/step - loss: 66815143.6676 - val_loss: 66934033.2721\n",
      "Epoch 17/50\n",
      "257754/257754 [==============================] - 127s 494us/step - loss: 66249409.3407 - val_loss: 59914779.4715\n",
      "Epoch 18/50\n",
      "257754/257754 [==============================] - 127s 491us/step - loss: 59579213.2764 - val_loss: 59593893.9050\n",
      "Epoch 19/50\n",
      "257754/257754 [==============================] - 126s 491us/step - loss: 59352791.1097 - val_loss: 59429937.8343\n",
      "Epoch 20/50\n",
      "257754/257754 [==============================] - 126s 488us/step - loss: 59238033.1023 - val_loss: 59330820.7227\n",
      "Epoch 21/50\n",
      "257754/257754 [==============================] - 126s 489us/step - loss: 59133837.4050 - val_loss: 59269496.6874\n",
      "Epoch 22/50\n",
      "257754/257754 [==============================] - 126s 488us/step - loss: 59078783.5923 - val_loss: 59181286.4900\n",
      "Epoch 23/50\n",
      "257754/257754 [==============================] - 126s 488us/step - loss: 58992802.1402 - val_loss: 59102319.3097\n",
      "Epoch 24/50\n",
      "257754/257754 [==============================] - 127s 491us/step - loss: 58915798.6203 - val_loss: 59019129.1865\n",
      "Epoch 25/50\n",
      "257754/257754 [==============================] - 126s 490us/step - loss: 58800384.6638 - val_loss: 58907514.0838\n",
      "Epoch 26/50\n",
      "257754/257754 [==============================] - 129s 500us/step - loss: 58681038.3299 - val_loss: 58765316.8824\n",
      "Epoch 27/50\n",
      "257754/257754 [==============================] - 126s 491us/step - loss: 58555646.2612 - val_loss: 58654877.3193\n",
      "Epoch 28/50\n",
      "257754/257754 [==============================] - 126s 489us/step - loss: 58436955.8591 - val_loss: 58506914.4667\n",
      "Epoch 29/50\n",
      "257754/257754 [==============================] - 126s 488us/step - loss: 58314431.7557 - val_loss: 58436447.9649\n",
      "Epoch 30/50\n",
      "257754/257754 [==============================] - 126s 489us/step - loss: 58236632.4329 - val_loss: 58346694.3723\n",
      "Epoch 31/50\n",
      "257754/257754 [==============================] - 126s 489us/step - loss: 58150098.4448 - val_loss: 58258226.2290\n",
      "Epoch 32/50\n",
      "257754/257754 [==============================] - 127s 491us/step - loss: 58049057.9289 - val_loss: 58152136.7716\n",
      "Epoch 33/50\n",
      "257754/257754 [==============================] - 126s 490us/step - loss: 48111713.5742 - val_loss: 37095637.6392\n",
      "Epoch 34/50\n",
      "257754/257754 [==============================] - 126s 490us/step - loss: 36921515.2894 - val_loss: 36971962.9448\n",
      "Epoch 35/50\n",
      "257754/257754 [==============================] - 126s 489us/step - loss: 36818164.0940 - val_loss: 36874753.1815\n",
      "Epoch 36/50\n",
      "257754/257754 [==============================] - 126s 489us/step - loss: 36749413.6711 - val_loss: 36821512.9908\n",
      "Epoch 37/50\n",
      "257754/257754 [==============================] - 126s 491us/step - loss: 36685723.5224 - val_loss: 36767669.1918\n",
      "Epoch 38/50\n",
      "257754/257754 [==============================] - 128s 497us/step - loss: 36634859.7029 - val_loss: 36804638.1909\n",
      "Epoch 39/50\n",
      "257754/257754 [==============================] - 129s 500us/step - loss: 36550337.1647 - val_loss: 36630887.5637\n",
      "Epoch 40/50\n",
      "257754/257754 [==============================] - 130s 502us/step - loss: 36488603.0547 - val_loss: 36560838.6149\n",
      "Epoch 41/50\n",
      "257754/257754 [==============================] - 125s 484us/step - loss: 36431497.2149 - val_loss: 36511132.9838\n",
      "Epoch 42/50\n",
      "257754/257754 [==============================] - 126s 490us/step - loss: 36378068.8407 - val_loss: 36469537.5322\n",
      "Epoch 43/50\n",
      "257754/257754 [==============================] - 128s 496us/step - loss: 36339447.8849 - val_loss: 36427780.3670\n",
      "Epoch 44/50\n",
      "257754/257754 [==============================] - 128s 495us/step - loss: 36305853.1078 - val_loss: 36399457.2598\n",
      "Epoch 45/50\n",
      "257754/257754 [==============================] - 128s 497us/step - loss: 36282948.7344 - val_loss: 36398786.3536\n",
      "Epoch 46/50\n",
      "257754/257754 [==============================] - 128s 495us/step - loss: 36269063.1186 - val_loss: 36379101.8737\n",
      "Epoch 47/50\n",
      "257754/257754 [==============================] - 128s 496us/step - loss: 36256358.6224 - val_loss: 36358312.1573\n",
      "Epoch 48/50\n",
      "257754/257754 [==============================] - 128s 496us/step - loss: 31495737.8118 - val_loss: 29266871.1321\n",
      "Epoch 49/50\n",
      "257754/257754 [==============================] - 128s 496us/step - loss: 29132709.6344 - val_loss: 29210538.6554\n",
      "Epoch 50/50\n",
      "257754/257754 [==============================] - 128s 495us/step - loss: 29115907.7457 - val_loss: 29196568.9866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f415565e550>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder.save('encoder_ elu.h5')\n",
    "decoder.save('decoder_elu.h5')\n",
    "autoencoder.save('autoencoder_elu.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG",
   "language": "python",
   "name": "eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
