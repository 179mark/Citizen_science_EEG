{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we compare models of different depth and architecture on clear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"TkAgg\")\n",
    "\n",
    "from sklearn.preprocessing import normalize#, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import mne\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, GRU, LSTM, Lambda, RepeatVector, Reshape, Dropout, Conv1D, UpSampling1D, Bidirectional\n",
    "\n",
    "from os import walk, listdir\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "data_path = \"../../data/train/\"\n",
    "clear_data_path = \"/media/valbub/Docs/data/train/\"\n",
    "raw_data_path = \"../../data/resting_state/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(object):\n",
    "    def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (7, 29), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "            \n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (np.array(X) - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def prepare_clear_data(self, data_path, limit=2):\n",
    "        train_eeg_dir = data_path\n",
    "        train_eeg_names = [x for x in listdir(train_eeg_dir) \n",
    "                         if x[-3:] == \".h5\"]\n",
    "        data = np.zeros((0, self.input_dim[0], self.input_dim[1]))\n",
    "\n",
    "        flag = 0\n",
    "        err_files = 0\n",
    "        for eeg_name in train_eeg_names:\n",
    "            if flag == limit:\n",
    "                break\n",
    "            flag += 1\n",
    "            h5_file = h5py.File(train_eeg_dir + eeg_name, 'r')\n",
    "            a_group_key = list(h5_file.keys())[0]\n",
    "            eeg_data = np.array(h5_file[a_group_key]).T\n",
    "            batches = np.array(self._getBatches(eeg_data, batch_size=self.input_dim[0]))\n",
    "            data = np.concatenate((data, batches), axis=0)\n",
    "        return data\n",
    "    \n",
    "    def prepare_raw_data(self, data_path, limit=2):\n",
    "        def preparefile(file_path):\n",
    "            raw = np.array(mne.io.read_raw_brainvision(file_path, preload=True).to_data_frame())\n",
    "            batches = np.array(self._getBatches(raw, batch_size=self.input_dim[0]))\n",
    "            del raw\n",
    "            return batches\n",
    "        files = []\n",
    "        data = []\n",
    "        for elem in walk(data_path):\n",
    "            for file in elem[-1]:\n",
    "                if file[-4:] == \"vhdr\":\n",
    "                    files.append(file)\n",
    "        data = np.ndarray(shape=(0, self.input_dim[0], self.input_dim[1]))\n",
    "        flag = 0\n",
    "        for file in files:\n",
    "            flag += 1\n",
    "            file_name = data_path + file\n",
    "            if flag == limit:\n",
    "                break\n",
    "            batches =  preparefile(file_name)\n",
    "            data = np.concatenate((data, batches), axis=0)\n",
    "        return data\n",
    "    \n",
    "    def fit(self, X_train, epochs=50):\n",
    "        X_scaled = self.scaler.fit_transform(X_train)\n",
    "        return self.autoencoder.fit(X_scaled, X_scaled, epochs = epochs)\n",
    "    \n",
    "    def fit_scaler(self, X_train):\n",
    "        self.scaler.fit_transform(X_train)\n",
    "    \n",
    "    def encode(self, df):\n",
    "        return self._predict(df, self.encoder, self.input_dim[0])\n",
    "    \n",
    "    def decode(self, df):\n",
    "        return self._predict(df, self.decoder, self.encoded_dim[1])\n",
    "    \n",
    "    def run(self, df):\n",
    "        return self._predict(df, self.autoencoder, self.input_dim[0])\n",
    "    \n",
    "    def save(self, path, part=\"autoencoder\"):\n",
    "        if part == \"encoder\":\n",
    "            self.encoder.save(path)\n",
    "        elif part == \"decoder\":\n",
    "            self.decoder.save(path)\n",
    "        elif part == \"autoencoder\":\n",
    "            self.autoencoder.save(path)\n",
    "        pass\n",
    "    \n",
    "    def load(self, path, part=\"autoencoder\", X_train=None):\n",
    "        if part == \"encoder\":\n",
    "            self.encoder = keras.models.load_model(path)\n",
    "        elif part == \"decoder\":\n",
    "            self.decoder = keras.models.load_model(path)\n",
    "        elif part == \"autoencoder\":\n",
    "            self.autoencoder = keras.models.load_model(path)\n",
    "        if x_train is not None:\n",
    "            self.fit_scaler(X_train)\n",
    "    \n",
    "\n",
    "    def _predict(self, df, model):\n",
    "        batches = self.scaler.transform(df)\n",
    "        batches = tuple(self._predictBatch(batch.reshape((1, *batch.shape)), model) for batch in batches)\n",
    "        batches = self._concatBatches(batches) \n",
    "        return self.scaler.reverse_transform(batches)\n",
    "    \n",
    "    def _predictBatch(self, batch, model):\n",
    "        return model.predict(batch)\n",
    "    \n",
    "    def _getBatches(self, arr, batch_size, axis=0):\n",
    "        n_batches = arr.shape[axis] // batch_size\n",
    "        result = np.array_split(arr, n_batches, axis=axis)\n",
    "        i = 0\n",
    "        while result[i].shape[0] != batch_size:\n",
    "            i += 1\n",
    "        result = result[i:]\n",
    "        return result\n",
    "    \n",
    "    def _concatBatches(self, batches, axis=0):\n",
    "        return np.concatenate(batches, axis=axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_1(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (7, 29), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._flat = Flatten()(self._inputs)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._flat)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=(encoded_dim[0]*encoded_dim[1],))\n",
    "            self._flat_decoded = Dense(input_dim[0]*input_dim[1], activation=activation[1])(self._encoded_inputs)\n",
    "            self._decoded = Reshape(input_dim)(self._flat_decoded)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "            \n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (np.array(X) - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_2(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (7, 29), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._conv = Conv1D(filters=encoded_dim[1], kernel_size=kernel)(self._inputs) \n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._conv)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._decoded = Reshape(input_dim)(self._flat_decoded)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "\n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "            \n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_3(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (7, 29), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7,\n",
    "                 folds=100):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._lambda = Lambda(lambda x: K.round(x * folds) / folds)(self._inputs)\n",
    "            self._lstm = LSTM(input_dim[1], return_sequences=True, dropout=0, recurrent_dropout=0.1)(self._lambda)\n",
    "            self._conv = Conv1D(filters=encoded_dim[1], kernel_size=input_dim[0])(self._lstm)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._conv)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "            \n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded_1 = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._flat_decoded_2 = UpSampling1D(size=input_dim[0] // encoded_dim[0])(self._flat_decoded_1)\n",
    "            self._lstm_2 = LSTM(input_dim[1], return_sequences=True)(self._flat_decoded_2)\n",
    "            self._decoded = Reshape(input_dim)(self._lstm_2)\n",
    "            \n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "            \n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "            \n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))  + 1e-10\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_3_5(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (7, 29), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._lstm = GRU(input_dim[1], return_sequences=True, dropout=0, recurrent_dropout=0.1)(self._inputs)\n",
    "            self._conv = Conv1D(filters=encoded_dim[1], kernel_size=input_dim[0])(self._lstm)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._conv)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded_1 = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._flat_decoded_2 = UpSampling1D(size=input_dim[0] // encoded_dim[0])(self._flat_decoded_1)\n",
    "            self._lstm_2 = GRU(input_dim[1], return_sequences=True)(self._flat_decoded_2)\n",
    "            self._decoded = Reshape(input_dim)(self._lstm_2)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "\n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1)) + 1e-10\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_4(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (7, 29), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7,\n",
    "                 folds = 100):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._lambda = Lambda(lambda x: K.round(x * folds) / folds)(self._inputs)\n",
    "            self._lstm = LSTM(input_dim[1], return_sequences=True, dropout=0, recurrent_dropout=0.1)(self._lambda)\n",
    "            self._reshape = Reshape((-1, input_dim[1] * input_dim[0]))(self._lstm)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._reshape)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded_1 = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._lstm_2 = LSTM(input_dim[1] * input_dim[0], return_sequences=True)(self._flat_decoded_1)\n",
    "            self._decoded = Reshape((-1, input_dim[1]))(self._lstm_2)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "\n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1)) + 1e-10\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epoch_numb = 50\n",
    "limit = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 29 and 203 for 'model_2/dense_2/MatMul' (op: 'MatMul') with input shapes: [?,29], [203,406].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 29 and 203 for 'model_2/dense_2/MatMul' (op: 'MatMul') with input shapes: [?,29], [203,406].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c0092838ccaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# here we get data for all experiments in future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mau_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAU_Stage_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mau_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_clear_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a4eeb4b666a0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, encoded_dim, loss, optimizer, activation, kernel)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2079\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2230\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2233\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2234\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_permute_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m         return tf.reshape(tf.matmul(xt, yt),\n\u001b[0m\u001b[1;32m   1068\u001b[0m                           x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2122\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4277\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4278\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4279\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4280\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4281\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 29 and 203 for 'model_2/dense_2/MatMul' (op: 'MatMul') with input shapes: [?,29], [203,406]."
     ]
    }
   ],
   "source": [
    "# here we get data for all experiments in future\n",
    "au_1 = AU_Stage_1()\n",
    "data_set = au_1.prepare_clear_data(clear_data_path, limit=limit)\n",
    "train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "au_1.fit(train_data, epochs=epoch_numb)\n",
    "folder = \"./model_stage_1/\"\n",
    "au_1.save(folder + \"au\")\n",
    "au_1.save(folder + \"en\")\n",
    "au_1.save(folder + \"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = au_1._predict(test_data, au_1.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print('\\nDense')\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4f2236764ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mau_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAU_Stage_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# here we assume that batches are the same and use data from previous model to compare models correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# data_set = au_2.prepare_clear_data(clear_data_path, limit=limit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-139fe38aca4b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, encoded_dim, loss, optimizer, activation, kernel)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoded_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoded_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_decoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#Models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;31m# Inferring the output shape is only relevant for Theano.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;31m# input shape known? then we can compute the output shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             return (input_shape[0],) + self._fix_unknown_dimension(\n\u001b[0;32m--> 402\u001b[0;31m                 input_shape[1:], self.target_shape)\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "au_2 = AU_Stage_2()\n",
    "# here we assume that batches are the same and use data from previous model to compare models correctly\n",
    "# data_set = au_2.prepare_clear_data(clear_data_path, limit=limit)\n",
    "# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "\n",
    "au_2.fit(train_data, epochs=epoch_numb)\n",
    "folder = \"./model_stage_2/\"\n",
    "au_2.save(folder + \"au\")\n",
    "au_2.save(folder + \"en\")\n",
    "au_2.save(folder + \"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = au_2._predict(test_data, au_2.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print('\\nDense+Conv')\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2c274dc58518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mau_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_numb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./model_stage_3/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mau_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"au\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "au_3 = AU_Stage_3()\n",
    "# here we assume that batches are the same and use data from previous model to compare models correctly\n",
    "# data_set = au_3.prepare_clear_data(clear_data_path, limit=limit)\n",
    "# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "\n",
    "au_3.fit(train_data, epochs=epoch_numb)\n",
    "folder = \"./model_stage_3/\"\n",
    "au_3.save(folder + \"au\")\n",
    "au_3.save(folder + \"en\")\n",
    "au_3.save(folder + \"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = au_3._predict(test_data, au_3.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print(\"\\nDense+Conv+LSTM\")\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "au_3_5 = AU_Stage_3_5()\n",
    "# here we assume that batches are the same and use data from previous model to compare models correctly\n",
    "# data_set = au_3_5.prepare_clear_data(clear_data_path, limit=limit)\n",
    "# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "\n",
    "au_3_5.fit(train_data, epochs=epoch_numb)\n",
    "folder = \"./model_stage_3_5/\"\n",
    "au_3_5.save(folder + \"au\")\n",
    "au_3_5.save(folder + \"en\")\n",
    "au_3_5.save(folder + \"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = au_3_5._predict(test_data, au_3_5.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print(\"\\nDense+Conv+GRU\")\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_4 = AU_Stage_4()\n",
    "# here we assume that batches are the same and use data from previous model to compare models correctly\n",
    "# data_set = au_4.prepare_clear_data(clear_data_path, limit=limit)\n",
    "# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "\n",
    "au_4.fit(train_data, epochs=epoch_numb)\n",
    "folder = \"./model_stage_4/\"\n",
    "au_4.save(folder + \"au\")\n",
    "au_4.save(folder + \"en\")\n",
    "au_4.save(folder + \"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = au_4._predict(test_data, au_4.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print(\"\\nDense+LSTM\")\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    + попробовать обучить всё это же, но без лямбды\n",
    "    + попробовать размер батча 5\n",
    "    + попробовать сжимать из (7, 58) в (7, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
