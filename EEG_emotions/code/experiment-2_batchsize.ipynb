{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we compare different batch sizes on clear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"TkAgg\")\n",
    "\n",
    "from sklearn.preprocessing import normalize#, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import mne\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, LSTM, RepeatVector, Reshape, Dropout, Conv1D, UpSampling1D, Bidirectional\n",
    "\n",
    "from os import walk, listdir\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "data_path = \"../../data/train/\"\n",
    "clear_data_path = \"/media/valbub/Docs/data/train/\"\n",
    "raw_data_path = \"../../data/resting_state/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(object):\n",
    "    def __init__(self, \n",
    "             input_dim = (5, 58), \n",
    "             encoded_dim = (1, 58), \n",
    "             loss=\"mse\", \n",
    "             optimizer=\"adadelta\", \n",
    "             activation=(\"relu\", \"sigmoid\", \"tanh\", \"elu\"),\n",
    "             act_idx=(0, 0),\n",
    "             kernel = 3):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "    \n",
    "    def prepare_clear_data(self, data_path, limit=2):\n",
    "        train_eeg_dir = data_path\n",
    "        train_eeg_names = [x for x in listdir(train_eeg_dir) \n",
    "                         if x[-3:] == \".h5\"]\n",
    "        data = np.zeros((0, self.input_dim[0], self.input_dim[1]))\n",
    "\n",
    "        flag = 0\n",
    "        for eeg_name in train_eeg_names:\n",
    "            if flag == limit:\n",
    "                break\n",
    "            flag += 1\n",
    "            h5_file = h5py.File(train_eeg_dir + eeg_name, 'r')\n",
    "            a_group_key = list(h5_file.keys())[0]\n",
    "            eeg_data = np.array(h5_file[a_group_key]).T\n",
    "            batches = np.array(self._getBatches(eeg_data, batch_size=self.input_dim[0]))\n",
    "            if len(batches.shape) == 3:\n",
    "                data = np.concatenate((data, batches), axis=0)\n",
    "            else:\n",
    "                flag -= 1\n",
    "        return data\n",
    "    \n",
    "    def prepare_raw_data(self, data_path, limit=2):\n",
    "        def preparefile(file_path):\n",
    "            raw = np.array(mne.io.read_raw_brainvision(file_path, preload=True).to_data_frame())\n",
    "            batches = np.array(self._getBatches(raw, batch_size=self.input_dim[0]))\n",
    "            del raw\n",
    "            return batches\n",
    "        files = []\n",
    "        data = []\n",
    "        for elem in walk(data_path):\n",
    "            for file in elem[-1]:\n",
    "                if file[-4:] == \"vhdr\":\n",
    "                    files.append(file)\n",
    "        data = np.ndarray(shape=(0, self.input_dim[0], self.input_dim[1]))\n",
    "        flag = 0\n",
    "        for file in files:\n",
    "            file_name = data_path + file\n",
    "            if flag == limit:\n",
    "                break\n",
    "            batches =  preparefile(file_name)\n",
    "            data = np.concatenate((data, batches), axis=0)\n",
    "            flag += 1\n",
    "        return data\n",
    "    \n",
    "    def fit(self, X_train, epochs=50):\n",
    "        X_scaled = self.scaler.fit_transform(X_train)\n",
    "        self.autoencoder.fit(X_scaled, X_scaled, epochs = epochs)\n",
    "    \n",
    "    def encode(self, df):\n",
    "        return self._predict(df, self.encoder, self.input_dim[0])\n",
    "    \n",
    "    def decode(self, df):\n",
    "        return self._predict(df, self.decoder, self.encoded_dim[1])\n",
    "    \n",
    "    def run(self, df):\n",
    "        return self._predict(df, self.autoencoder, self.input_dim[0])\n",
    "    \n",
    "    def save(self, path, part=\"autoencoder\"):\n",
    "        if part == \"encoder\":\n",
    "            self.encoder.save(path)\n",
    "        elif part == \"decoder\":\n",
    "            self.decoder.save(path)\n",
    "        elif part == \"autoencoder\":\n",
    "            self.autoencoder.save(path)\n",
    "        elif part == \"model\":\n",
    "            self.save(path)\n",
    "        pass\n",
    "    \n",
    "    def load(self, path, part=\"autoencoder\"):\n",
    "        if part == \"encoder\":\n",
    "            self.encoder = keras.models.load_model(path)\n",
    "        elif part == \"decoder\":\n",
    "            self.decoder = keras.models.load_model(path)\n",
    "        elif part == \"autoencoder\":\n",
    "            self.autoencoder = keras.models.load_model(path)\n",
    "        elif part == \"model\":\n",
    "            self = keras.models.load_model(path)\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def _predict(self, df, model, batch_size):\n",
    "        batches = self.scaler.transform(df)\n",
    "        batches = tuple(self._predictBatch(batch.reshape((1, *batch.shape)), model) for batch in batches)\n",
    "        batches = self._concatBatches(batches) \n",
    "        return self.scaler.reverse_transform(batches)\n",
    "    \n",
    "    def _predictBatch(self, batch, model):\n",
    "        return model.predict(batch)\n",
    "    \n",
    "    def _getBatches(self, arr, batch_size, axis=0):\n",
    "        n_batches = arr.shape[axis] // batch_size\n",
    "        return np.array_split(arr, n_batches, axis=axis)\n",
    "    \n",
    "    def _concatBatches(self, batches, axis=0):\n",
    "        return np.concatenate(batches, axis=axis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_1(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (1, 58), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._flat = Flatten()(self._inputs)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._flat)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=(encoded_dim[0]*encoded_dim[1],))\n",
    "            self._flat_decoded = Dense(input_dim[0]*input_dim[1], activation=activation[1])(self._encoded_inputs)\n",
    "            self._decoded = Reshape(input_dim)(self._flat_decoded)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "            \n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (np.array(X) - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_2(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (5, 58), \n",
    "                 encoded_dim = (1, 58), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 5):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._conv = Conv1D(filters=encoded_dim[1], kernel_size=kernel)(self._inputs) \n",
    "            self._encoded = Dense(units=encoded_dim[1], activation=activation[0])(self._conv)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._decoded = Reshape(input_dim)(self._flat_decoded)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "\n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "            \n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epoch_numb = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        (None, 1, 58)             0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1, 290)            17110     \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 5, 58)             0         \n",
      "=================================================================\n",
      "Total params: 17,110\n",
      "Trainable params: 17,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "au_model = AU_Stage_2(input_dim=(5, 58), kernel=5)\n",
    "au_model.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 0.0019\n",
      "Epoch 2/50\n",
      "281155/281155 [==============================] - 10s 34us/step - loss: 7.7663e-04\n",
      "Epoch 3/50\n",
      "281155/281155 [==============================] - 10s 34us/step - loss: 6.6637e-04\n",
      "Epoch 4/50\n",
      "281155/281155 [==============================] - 10s 34us/step - loss: 5.7644e-04\n",
      "Epoch 5/50\n",
      "281155/281155 [==============================] - 10s 34us/step - loss: 5.0248e-04\n",
      "Epoch 6/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 4.4147e-04\n",
      "Epoch 7/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 3.9248e-04\n",
      "Epoch 8/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 3.5567e-04\n",
      "Epoch 9/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 3.2843e-04\n",
      "Epoch 10/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 3.0738e-04\n",
      "Epoch 11/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.9034e-04\n",
      "Epoch 12/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.7575e-04\n",
      "Epoch 13/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.6288e-04\n",
      "Epoch 14/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.5124e-04\n",
      "Epoch 15/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.4059e-04\n",
      "Epoch 16/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.3089e-04\n",
      "Epoch 17/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.2201e-04\n",
      "Epoch 18/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.1384e-04\n",
      "Epoch 19/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 2.0621e-04\n",
      "Epoch 20/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.9909e-04\n",
      "Epoch 21/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.9242e-04\n",
      "Epoch 22/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.8621e-04\n",
      "Epoch 23/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.8040e-04\n",
      "Epoch 24/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.7501e-04\n",
      "Epoch 25/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.6997e-04\n",
      "Epoch 26/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.6525e-04\n",
      "Epoch 27/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.6088e-04\n",
      "Epoch 28/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.5680e-04\n",
      "Epoch 29/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.5296e-04\n",
      "Epoch 30/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.4939e-04\n",
      "Epoch 31/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.4607e-04\n",
      "Epoch 32/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.4294e-04\n",
      "Epoch 33/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.4005e-04\n",
      "Epoch 34/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.3734e-04\n",
      "Epoch 35/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.3476e-04\n",
      "Epoch 36/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.3239e-04\n",
      "Epoch 37/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.3013e-04\n",
      "Epoch 38/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.2801e-04\n",
      "Epoch 39/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.2602e-04\n",
      "Epoch 40/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.2413e-04\n",
      "Epoch 41/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.2235e-04\n",
      "Epoch 42/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.2061e-04\n",
      "Epoch 43/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.1897e-04\n",
      "Epoch 44/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.1740e-04\n",
      "Epoch 45/50\n",
      "281155/281155 [==============================] - 10s 36us/step - loss: 1.1591e-04\n",
      "Epoch 46/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.1448e-04\n",
      "Epoch 47/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.1309e-04\n",
      "Epoch 48/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.1177e-04\n",
      "Epoch 49/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.1047e-04\n",
      "Epoch 50/50\n",
      "281155/281155 [==============================] - 10s 35us/step - loss: 1.0924e-04\n",
      "3 :\n",
      "0.9355267609929022\n",
      "1.4353611306033853e-06\n",
      "1.4855373024882978e-11\n",
      "\n",
      "Epoch 1/50\n",
      "168693/168693 [==============================] - 8s 48us/step - loss: 0.0029\n",
      "Epoch 2/50\n",
      "168693/168693 [==============================] - 8s 46us/step - loss: 0.0011\n",
      "Epoch 3/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 8.5907e-04\n",
      "Epoch 4/50\n",
      "168693/168693 [==============================] - 8s 44us/step - loss: 7.9961e-04\n",
      "Epoch 5/50\n",
      "168693/168693 [==============================] - 8s 46us/step - loss: 7.5351e-04\n",
      "Epoch 6/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 7.0369e-04\n",
      "Epoch 7/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 6.5350e-04\n",
      "Epoch 8/50\n",
      "168693/168693 [==============================] - 7s 44us/step - loss: 6.0746e-04\n",
      "Epoch 9/50\n",
      "168693/168693 [==============================] - 7s 44us/step - loss: 5.6677e-04\n",
      "Epoch 10/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 5.3149e-04\n",
      "Epoch 11/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 5.0119e-04\n",
      "Epoch 12/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 4.7485e-04\n",
      "Epoch 13/50\n",
      "168693/168693 [==============================] - 8s 46us/step - loss: 4.5168e-04\n",
      "Epoch 14/50\n",
      "168693/168693 [==============================] - 8s 47us/step - loss: 4.3107e-04\n",
      "Epoch 15/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 4.1274e-04\n",
      "Epoch 16/50\n",
      "168693/168693 [==============================] - 7s 43us/step - loss: 3.9629e-04\n",
      "Epoch 17/50\n",
      "168693/168693 [==============================] - 7s 44us/step - loss: 3.8163e-04\n",
      "Epoch 18/50\n",
      "168693/168693 [==============================] - 7s 44us/step - loss: 3.6862e-04\n",
      "Epoch 19/50\n",
      "168693/168693 [==============================] - 7s 43us/step - loss: 3.5708e-04\n",
      "Epoch 20/50\n",
      "168693/168693 [==============================] - 7s 44us/step - loss: 3.4685e-04\n",
      "Epoch 21/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 3.3777e-04\n",
      "Epoch 22/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 3.2972e-04\n",
      "Epoch 23/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 3.2238e-04\n",
      "Epoch 24/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 3.1563e-04\n",
      "Epoch 25/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 3.0933e-04\n",
      "Epoch 26/50\n",
      "168693/168693 [==============================] - 7s 44us/step - loss: 3.0334e-04\n",
      "Epoch 27/50\n",
      "168693/168693 [==============================] - 8s 47us/step - loss: 2.9765e-04\n",
      "Epoch 28/50\n",
      "168693/168693 [==============================] - 8s 46us/step - loss: 2.9216e-04\n",
      "Epoch 29/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.8685e-04\n",
      "Epoch 30/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.8172e-04\n",
      "Epoch 31/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.7673e-04\n",
      "Epoch 32/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.7199e-04\n",
      "Epoch 33/50\n",
      "168693/168693 [==============================] - 8s 46us/step - loss: 2.6741e-04\n",
      "Epoch 34/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.6305e-04\n",
      "Epoch 35/50\n",
      "168693/168693 [==============================] - 8s 46us/step - loss: 2.5885e-04\n",
      "Epoch 36/50\n",
      "168693/168693 [==============================] - 8s 46us/step - loss: 2.5484e-04\n",
      "Epoch 37/50\n",
      "168693/168693 [==============================] - 8s 49us/step - loss: 2.5104e-04\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.4742e-04\n",
      "Epoch 39/50\n",
      "168693/168693 [==============================] - 7s 43us/step - loss: 2.4395e-04\n",
      "Epoch 40/50\n",
      "168693/168693 [==============================] - 7s 42us/step - loss: 2.4064e-04\n",
      "Epoch 41/50\n",
      "168693/168693 [==============================] - 7s 42us/step - loss: 2.3743e-04\n",
      "Epoch 42/50\n",
      "168693/168693 [==============================] - 7s 43us/step - loss: 2.3441e-04\n",
      "Epoch 43/50\n",
      "168693/168693 [==============================] - 7s 42us/step - loss: 2.3140e-04\n",
      "Epoch 44/50\n",
      "168693/168693 [==============================] - 7s 44us/step - loss: 2.2857e-04\n",
      "Epoch 45/50\n",
      "168693/168693 [==============================] - 8s 46us/step - loss: 2.2582e-04\n",
      "Epoch 46/50\n",
      "168693/168693 [==============================] - 7s 42us/step - loss: 2.2316e-04\n",
      "Epoch 47/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.2056e-04\n",
      "Epoch 48/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.1808e-04\n",
      "Epoch 49/50\n",
      "168693/168693 [==============================] - 8s 45us/step - loss: 2.1562e-04\n",
      "Epoch 50/50\n",
      "168693/168693 [==============================] - 7s 43us/step - loss: 2.1319e-04\n",
      "5 :\n",
      "0.885035668950525\n",
      "1.9683108128532147e-06\n",
      "2.2997870921230004e-11\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8fa00362f941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mau_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mau_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mau_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4686df48177f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-ecc26f2f639d>\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     return _methods._amin(a, axis=axis,\n\u001b[0;32m-> 2420\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "bs = [3, 5]\n",
    "history = []\n",
    "\n",
    "for batch_size in bs:\n",
    "        au_model = AU_Stage_2(input_dim=(batch_size, 58), kernel=batch_size)\n",
    "        data_set = au_model.prepare_clear_data(clear_data_path, limit=2)\n",
    "        train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "        \n",
    "        au_model.fit(train_data, epochs=50)\n",
    "\n",
    "        pr = au_model._predict(test_data, au_model.autoencoder, batch_size=batch_size)\n",
    "        ds = np.concatenate(test_data)\n",
    "        p = np.concatenate(pr)\n",
    "        history.append({'batch_size': batch_size, 'r2': sklearn.metrics.r2_score(ds, p), 'MSE': sklearn.metrics.mean_squared_error(ds, p), 'MAE': sklearn.metrics.mean_absolute_error(ds, p)})\n",
    "        print(batch_size, ':')\n",
    "        print(sklearn.metrics.r2_score(ds, p))\n",
    "        print(sklearn.metrics.mean_absolute_error(ds, p))\n",
    "        print(sklearn.metrics.mean_squared_error(ds, p))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30275/30275 [==============================] - 2s 77us/step - loss: 0.0102\n",
      "Epoch 2/50\n",
      "30275/30275 [==============================] - 2s 63us/step - loss: 0.0077\n",
      "Epoch 3/50\n",
      "30275/30275 [==============================] - 2s 63us/step - loss: 0.0046\n",
      "Epoch 4/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0031\n",
      "Epoch 5/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 0.0026\n",
      "Epoch 6/50\n",
      "30275/30275 [==============================] - 2s 63us/step - loss: 0.0023\n",
      "Epoch 7/50\n",
      "30275/30275 [==============================] - 2s 63us/step - loss: 0.0022\n",
      "Epoch 8/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 0.0021\n",
      "Epoch 9/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 0.0020\n",
      "Epoch 10/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0020\n",
      "Epoch 11/50\n",
      "30275/30275 [==============================] - 2s 63us/step - loss: 0.0019\n",
      "Epoch 12/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 0.0018\n",
      "Epoch 13/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 0.0018\n",
      "Epoch 14/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 0.0017\n",
      "Epoch 15/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0017\n",
      "Epoch 16/50\n",
      "30275/30275 [==============================] - 2s 66us/step - loss: 0.0016\n",
      "Epoch 17/50\n",
      "30275/30275 [==============================] - 2s 69us/step - loss: 0.0016\n",
      "Epoch 18/50\n",
      "30275/30275 [==============================] - 2s 68us/step - loss: 0.0015\n",
      "Epoch 19/50\n",
      "30275/30275 [==============================] - 2s 69us/step - loss: 0.0015\n",
      "Epoch 20/50\n",
      "30275/30275 [==============================] - 2s 69us/step - loss: 0.0014\n",
      "Epoch 21/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0014\n",
      "Epoch 22/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0013\n",
      "Epoch 23/50\n",
      "30275/30275 [==============================] - 2s 63us/step - loss: 0.0013\n",
      "Epoch 24/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0012\n",
      "Epoch 25/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0012\n",
      "Epoch 26/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0012\n",
      "Epoch 27/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0012\n",
      "Epoch 28/50\n",
      "30275/30275 [==============================] - 2s 66us/step - loss: 0.0011\n",
      "Epoch 29/50\n",
      "30275/30275 [==============================] - 2s 72us/step - loss: 0.0011\n",
      "Epoch 30/50\n",
      "30275/30275 [==============================] - 2s 69us/step - loss: 0.0011\n",
      "Epoch 31/50\n",
      "30275/30275 [==============================] - 2s 67us/step - loss: 0.0011\n",
      "Epoch 32/50\n",
      "30275/30275 [==============================] - 2s 69us/step - loss: 0.0010\n",
      "Epoch 33/50\n",
      "30275/30275 [==============================] - 2s 69us/step - loss: 0.0010\n",
      "Epoch 34/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 0.0010\n",
      "Epoch 35/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 9.9312e-04\n",
      "Epoch 36/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 9.8860e-04\n",
      "Epoch 37/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 9.7049e-04\n",
      "Epoch 38/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 9.7081e-04\n",
      "Epoch 39/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 9.5108e-04\n",
      "Epoch 40/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 9.4054e-04\n",
      "Epoch 41/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 9.3314e-04\n",
      "Epoch 42/50\n",
      "30275/30275 [==============================] - 2s 64us/step - loss: 9.2037e-04\n",
      "Epoch 43/50\n",
      "30275/30275 [==============================] - 2s 65us/step - loss: 9.1238e-04\n",
      "Epoch 44/50\n",
      "30275/30275 [==============================] - 2s 63us/step - loss: 9.0161e-04\n",
      "Epoch 45/50\n",
      "30275/30275 [==============================] - 2s 61us/step - loss: 8.9426e-04\n",
      "Epoch 46/50\n",
      "30275/30275 [==============================] - 2s 61us/step - loss: 8.8137e-04\n",
      "Epoch 47/50\n",
      "30275/30275 [==============================] - 2s 61us/step - loss: 8.6901e-04\n",
      "Epoch 48/50\n",
      "30275/30275 [==============================] - 2s 62us/step - loss: 8.6508e-04\n",
      "Epoch 49/50\n",
      "30275/30275 [==============================] - 2s 62us/step - loss: 8.5198e-04\n",
      "Epoch 50/50\n",
      "30275/30275 [==============================] - 2s 61us/step - loss: 8.4756e-04\n",
      "7 :\n",
      "0.9048461376510634\n",
      "1.045874503390704e-06\n",
      "1.8217765913821238e-12\n",
      "\n",
      "Epoch 1/50\n",
      "148043/148043 [==============================] - 10s 69us/step - loss: 0.0030\n",
      "Epoch 2/50\n",
      "148043/148043 [==============================] - 10s 66us/step - loss: 0.0016\n",
      "Epoch 3/50\n",
      "148043/148043 [==============================] - 10s 65us/step - loss: 0.0010\n",
      "Epoch 4/50\n",
      "148043/148043 [==============================] - 10s 65us/step - loss: 8.4454e-04\n",
      "Epoch 5/50\n",
      "148043/148043 [==============================] - 10s 66us/step - loss: 7.7508e-04\n",
      "Epoch 6/50\n",
      "148043/148043 [==============================] - 10s 66us/step - loss: 7.4701e-04\n",
      "Epoch 7/50\n",
      "148043/148043 [==============================] - 10s 66us/step - loss: 7.2728e-04\n",
      "Epoch 8/50\n",
      "148043/148043 [==============================] - 9s 64us/step - loss: 7.0685e-04\n",
      "Epoch 9/50\n",
      "148043/148043 [==============================] - 9s 64us/step - loss: 6.8245e-04\n",
      "Epoch 10/50\n",
      "148043/148043 [==============================] - 10s 65us/step - loss: 6.5324e-04\n",
      "Epoch 11/50\n",
      "148043/148043 [==============================] - 10s 65us/step - loss: 6.2076e-04\n",
      "Epoch 12/50\n",
      "148043/148043 [==============================] - 10s 65us/step - loss: 5.8870e-04\n",
      "Epoch 13/50\n",
      "148043/148043 [==============================] - 10s 65us/step - loss: 5.6070e-04\n",
      "Epoch 14/50\n",
      "148043/148043 [==============================] - 10s 64us/step - loss: 5.3795e-04\n",
      "Epoch 15/50\n",
      "148043/148043 [==============================] - 9s 63us/step - loss: 5.1953e-04\n",
      "Epoch 16/50\n",
      "148043/148043 [==============================] - 9s 63us/step - loss: 5.0380e-04\n",
      "Epoch 17/50\n",
      "148043/148043 [==============================] - 9s 63us/step - loss: 4.8968e-04\n",
      "Epoch 18/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 4.7645e-04\n",
      "Epoch 19/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 4.6392e-04\n",
      "Epoch 20/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 4.5201e-04\n",
      "Epoch 21/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 4.4084e-04\n",
      "Epoch 22/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 4.3047e-04\n",
      "Epoch 23/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 4.2080e-04\n",
      "Epoch 24/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 4.1193e-04\n",
      "Epoch 25/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 4.0372e-04\n",
      "Epoch 26/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.9617e-04\n",
      "Epoch 27/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.8917e-04\n",
      "Epoch 28/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.8267e-04\n",
      "Epoch 29/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.7659e-04\n",
      "Epoch 30/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.7090e-04\n",
      "Epoch 31/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.6561e-04\n",
      "Epoch 32/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.6057e-04\n",
      "Epoch 33/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.5584e-04\n",
      "Epoch 34/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.5136e-04\n",
      "Epoch 35/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.4711e-04\n",
      "Epoch 36/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.4303e-04\n",
      "Epoch 37/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.3912e-04\n",
      "Epoch 38/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.3533e-04\n",
      "Epoch 39/50\n",
      "148043/148043 [==============================] - 9s 63us/step - loss: 3.3168e-04\n",
      "Epoch 40/50\n",
      "148043/148043 [==============================] - 9s 63us/step - loss: 3.2811e-04\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.2459e-04\n",
      "Epoch 42/50\n",
      "148043/148043 [==============================] - 9s 64us/step - loss: 3.2116e-04\n",
      "Epoch 43/50\n",
      "148043/148043 [==============================] - 9s 64us/step - loss: 3.1773e-04\n",
      "Epoch 44/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 3.1435e-04\n",
      "Epoch 45/50\n",
      "148043/148043 [==============================] - 9s 63us/step - loss: 3.1102e-04\n",
      "Epoch 46/50\n",
      "148043/148043 [==============================] - 8s 54us/step - loss: 3.0771e-04\n",
      "Epoch 47/50\n",
      "148043/148043 [==============================] - 8s 54us/step - loss: 3.0445e-04\n",
      "Epoch 48/50\n",
      "148043/148043 [==============================] - 8s 56us/step - loss: 3.0121e-04\n",
      "Epoch 49/50\n",
      "148043/148043 [==============================] - 9s 58us/step - loss: 2.9802e-04\n",
      "Epoch 50/50\n",
      "148043/148043 [==============================] - 9s 62us/step - loss: 2.9486e-04\n",
      "10 :\n",
      "0.8393327698740133\n",
      "2.2765445397243576e-06\n",
      "2.5172499444772298e-11\n",
      "\n",
      "Epoch 1/50\n",
      "70542/70542 [==============================] - 5s 69us/step - loss: 0.0048\n",
      "Epoch 2/50\n",
      "70542/70542 [==============================] - 5s 64us/step - loss: 0.0038\n",
      "Epoch 3/50\n",
      "70542/70542 [==============================] - 5s 67us/step - loss: 0.0029\n",
      "Epoch 4/50\n",
      "70542/70542 [==============================] - 5s 75us/step - loss: 0.0020\n",
      "Epoch 5/50\n",
      "70542/70542 [==============================] - 5s 67us/step - loss: 0.0017\n",
      "Epoch 6/50\n",
      "70542/70542 [==============================] - 5s 64us/step - loss: 0.0015\n",
      "Epoch 7/50\n",
      "70542/70542 [==============================] - 4s 64us/step - loss: 0.0014\n",
      "Epoch 8/50\n",
      "70542/70542 [==============================] - 5s 64us/step - loss: 0.0013\n",
      "Epoch 9/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 0.0013\n",
      "Epoch 10/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 0.0012\n",
      "Epoch 11/50\n",
      "70542/70542 [==============================] - 5s 64us/step - loss: 0.0012\n",
      "Epoch 12/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 0.0011\n",
      "Epoch 13/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 0.0011\n",
      "Epoch 14/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 0.0011\n",
      "Epoch 15/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 0.0011\n",
      "Epoch 16/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 0.0010\n",
      "Epoch 17/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 0.0010\n",
      "Epoch 18/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 9.8964e-04\n",
      "Epoch 19/50\n",
      "70542/70542 [==============================] - 5s 69us/step - loss: 9.6678e-04\n",
      "Epoch 20/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 9.4376e-04\n",
      "Epoch 21/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 9.2150e-04\n",
      "Epoch 22/50\n",
      "70542/70542 [==============================] - 5s 70us/step - loss: 8.9973e-04\n",
      "Epoch 23/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 8.7892e-04\n",
      "Epoch 24/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 8.5880e-04\n",
      "Epoch 25/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 8.3957e-04\n",
      "Epoch 26/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 8.2203e-04\n",
      "Epoch 27/50\n",
      "70542/70542 [==============================] - 5s 64us/step - loss: 8.0472e-04\n",
      "Epoch 28/50\n",
      "70542/70542 [==============================] - 5s 64us/step - loss: 7.8771e-04\n",
      "Epoch 29/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 7.7176e-04\n",
      "Epoch 30/50\n",
      "70542/70542 [==============================] - 5s 67us/step - loss: 7.5612e-04\n",
      "Epoch 31/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 7.4305e-04\n",
      "Epoch 32/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 7.2901e-04\n",
      "Epoch 33/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 7.1572e-04\n",
      "Epoch 34/50\n",
      "70542/70542 [==============================] - 5s 73us/step - loss: 7.0340e-04\n",
      "Epoch 35/50\n",
      "70542/70542 [==============================] - 5s 70us/step - loss: 6.9249e-04\n",
      "Epoch 36/50\n",
      "70542/70542 [==============================] - 5s 72us/step - loss: 6.8135e-04\n",
      "Epoch 37/50\n",
      "70542/70542 [==============================] - 5s 67us/step - loss: 6.6977e-04\n",
      "Epoch 38/50\n",
      "70542/70542 [==============================] - 5s 65us/step - loss: 6.5896e-04\n",
      "Epoch 39/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 6.4915e-04\n",
      "Epoch 40/50\n",
      "70542/70542 [==============================] - 5s 64us/step - loss: 6.3905e-04\n",
      "Epoch 41/50\n",
      "70542/70542 [==============================] - 4s 64us/step - loss: 6.2971e-04\n",
      "Epoch 42/50\n",
      "70542/70542 [==============================] - 5s 71us/step - loss: 6.2215e-04\n",
      "Epoch 43/50\n",
      "70542/70542 [==============================] - 5s 72us/step - loss: 6.1168e-04\n",
      "Epoch 44/50\n",
      "70542/70542 [==============================] - 5s 69us/step - loss: 6.0395e-04\n",
      "Epoch 45/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 5.9528e-04\n",
      "Epoch 46/50\n",
      "70542/70542 [==============================] - 5s 68us/step - loss: 5.8818e-04\n",
      "Epoch 47/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 5.7955e-04\n",
      "Epoch 48/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 5.7261e-04\n",
      "Epoch 49/50\n",
      "70542/70542 [==============================] - 5s 70us/step - loss: 5.6583e-04\n",
      "Epoch 50/50\n",
      "70542/70542 [==============================] - 5s 66us/step - loss: 5.5958e-04\n",
      "12 :\n",
      "0.8133912910470965\n",
      "2.4991187545520596e-06\n",
      "2.2961386736280264e-11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bs = [7, 10, 12]\n",
    "\n",
    "for batch_size in bs:\n",
    "        au_model = AU_Stage_2(input_dim=(batch_size, 58), kernel=batch_size)\n",
    "        data_set = au_model.prepare_clear_data(clear_data_path, limit=4)\n",
    "        train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "        \n",
    "        au_model.fit(train_data, epochs=50)\n",
    "\n",
    "        pr = au_model._predict(test_data, au_model.autoencoder, batch_size=batch_size)\n",
    "        ds = np.concatenate(test_data)\n",
    "        p = np.concatenate(pr)\n",
    "        history.append({'batch_size': batch_size, 'r2': sklearn.metrics.r2_score(ds, p), 'MSE': sklearn.metrics.mean_squared_error(ds, p), 'MAE': sklearn.metrics.mean_absolute_error(ds, p)})\n",
    "        print(batch_size, ':')\n",
    "        print(sklearn.metrics.r2_score(ds, p))\n",
    "        print(sklearn.metrics.mean_absolute_error(ds, p))\n",
    "        print(sklearn.metrics.mean_squared_error(ds, p))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "r2: 0.9048461376510634\n",
      "MSE 1.8217765913821238e-12\n",
      "MAE 1.045874503390704e-06\n",
      "\n",
      "3\n",
      "r2: 0.9355267609929022\n",
      "MSE 1.4855373024882978e-11\n",
      "MAE 1.4353611306033853e-06\n",
      "\n",
      "12\n",
      "r2: 0.8133912910470965\n",
      "MSE 2.2961386736280264e-11\n",
      "MAE 2.4991187545520596e-06\n",
      "\n",
      "5\n",
      "r2: 0.885035668950525\n",
      "MSE 2.2997870921230004e-11\n",
      "MAE 1.9683108128532147e-06\n",
      "\n",
      "10\n",
      "r2: 0.8393327698740133\n",
      "MSE 2.5172499444772298e-11\n",
      "MAE 2.2765445397243576e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history.sort(key=lambda x: x['MSE'])\n",
    "\n",
    "for i in history:\n",
    "    print(i['batch_size'])\n",
    "    print('r2:', i['r2'])\n",
    "    print('MSE', i['MSE'])\n",
    "    print('MAE', i['MAE'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bs = [3, 5, 7, 10, 12]\n",
    "\n",
    "# for batch_size in bs:\n",
    "#         au_model = AU_Stage_1(input_dim=(batch_size, 58), kernel=batch_size)\n",
    "#         data_set = au_model.prepare_clear_data(clear_data_path, limit=4)\n",
    "#         train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "        \n",
    "#         au_model.fit(train_data, epochs=50)\n",
    "\n",
    "#         pr = au_model._predict(test_data, au_model.autoencoder, batch_size=batch_size)\n",
    "#         ds = np.concatenate(test_data)\n",
    "#         p = np.concatenate(pr)\n",
    "#         history.append({'batch_size': batch_size, 'r2': sklearn.metrics.r2_score(ds, p), 'MSE': sklearn.metrics.mean_squared_error(ds, p), 'MAE': sklearn.metrics.mean_absolute_error(ds, p)})\n",
    "#         print(batch_size, ':')\n",
    "#         print(sklearn.metrics.r2_score(ds, p))\n",
    "#         print(sklearn.metrics.mean_absolute_error(ds, p))\n",
    "#         print(sklearn.metrics.mean_squared_error(ds, p))\n",
    "#         print()\n",
    "#         del data_set\n",
    "#         del train_data\n",
    "#         del test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
