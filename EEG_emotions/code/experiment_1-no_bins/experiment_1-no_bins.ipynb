{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we compare models of different depth and architecture on clear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"TkAgg\")\n",
    "\n",
    "from sklearn.preprocessing import normalize#, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import mne\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, GRU, LSTM, Lambda, RepeatVector, Reshape, Dropout, Conv1D, UpSampling1D, Bidirectional\n",
    "\n",
    "from os import walk, listdir\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "data_path = \"../../../data/train/\"\n",
    "clear_data_path = \"/media/valbub/Docs/data/train/\"\n",
    "raw_data_path = \"../../../data/resting_state/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(object):\n",
    "    def __init__(self, \n",
    "             input_dim = (7, 58), \n",
    "             encoded_dim = (1, 58), \n",
    "             loss=\"mse\", \n",
    "             optimizer=\"adadelta\", \n",
    "             activation=(\"relu\", \"sigmoid\", \"tanh\", \"elu\"),\n",
    "             act_idx=(0, 0),\n",
    "             kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "            \n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (np.array(X) - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def prepare_clear_data(self, data_path, limit=2):\n",
    "        train_eeg_dir = data_path\n",
    "        train_eeg_names = [x for x in listdir(train_eeg_dir) \n",
    "                         if x[-3:] == \".h5\"]\n",
    "        data = np.zeros((0, self.input_dim[0], self.input_dim[1]))\n",
    "\n",
    "        flag = 0\n",
    "        err_files = 0\n",
    "        for eeg_name in train_eeg_names:\n",
    "            if flag == limit:\n",
    "                break\n",
    "            flag += 1\n",
    "            h5_file = h5py.File(train_eeg_dir + eeg_name, 'r')\n",
    "            a_group_key = list(h5_file.keys())[0]\n",
    "            eeg_data = np.array(h5_file[a_group_key]).T\n",
    "            batches = np.array(self._getBatches(eeg_data, batch_size=self.input_dim[0]))\n",
    "            data = np.concatenate((data, batches), axis=0)\n",
    "        return data\n",
    "    \n",
    "    def prepare_raw_data(self, data_path, limit=2):\n",
    "        def preparefile(file_path):\n",
    "            raw = np.array(mne.io.read_raw_brainvision(file_path, preload=True).to_data_frame())\n",
    "            batches = np.array(self._getBatches(raw, batch_size=self.input_dim[0]))\n",
    "            del raw\n",
    "            return batches\n",
    "        files = []\n",
    "        data = []\n",
    "        for elem in walk(data_path):\n",
    "            for file in elem[-1]:\n",
    "                if file[-4:] == \"vhdr\":\n",
    "                    files.append(file)\n",
    "        data = np.ndarray(shape=(0, self.input_dim[0], self.input_dim[1]))\n",
    "        flag = 0\n",
    "        for file in files:\n",
    "            flag += 1\n",
    "            file_name = data_path + file\n",
    "            if flag == limit:\n",
    "                break\n",
    "            batches =  preparefile(file_name)\n",
    "            data = np.concatenate((data, batches), axis=0)\n",
    "        return data\n",
    "    \n",
    "    def fit(self, X_train, epochs=50):\n",
    "        X_scaled = self.scaler.fit_transform(X_train)\n",
    "        return self.autoencoder.fit(X_scaled, X_scaled, epochs = epochs)\n",
    "    \n",
    "    def fit_scaler(self, X_train):\n",
    "        self.scaler.fit_transform(X_train)\n",
    "    \n",
    "    def encode(self, df):\n",
    "        return self._predict(df, self.encoder, self.input_dim[0])\n",
    "    \n",
    "    def decode(self, df):\n",
    "        return self._predict(df, self.decoder, self.encoded_dim[1])\n",
    "    \n",
    "    def run(self, df):\n",
    "        return self._predict(df, self.autoencoder, self.input_dim[0])\n",
    "    \n",
    "    def save(self, path, part=\"autoencoder\"):\n",
    "        if part == \"encoder\":\n",
    "            self.encoder.save(path)\n",
    "        elif part == \"decoder\":\n",
    "            self.decoder.save(path)\n",
    "        elif part == \"autoencoder\":\n",
    "            self.autoencoder.save(path)\n",
    "        pass\n",
    "    \n",
    "    def load(self, path, part=\"autoencoder\", X_train=None):\n",
    "        if part == \"encoder\":\n",
    "            self.encoder = keras.models.load_model(path)\n",
    "        elif part == \"decoder\":\n",
    "            self.decoder = keras.models.load_model(path)\n",
    "        elif part == \"autoencoder\":\n",
    "            self.autoencoder = keras.models.load_model(path)\n",
    "        if X_train is not None:\n",
    "            self.fit_scaler(X_train)\n",
    "    \n",
    "\n",
    "    def _predict(self, df, model):\n",
    "        batches = self.scaler.transform(df)\n",
    "        batches = tuple(self._predictBatch(batch.reshape((1, *batch.shape)), model) for batch in batches)\n",
    "        batches = self._concatBatches(batches) \n",
    "        return self.scaler.reverse_transform(batches)\n",
    "    \n",
    "    def _predictBatch(self, batch, model):\n",
    "        return model.predict(batch)\n",
    "    \n",
    "    def _getBatches(self, arr, batch_size, axis=0):\n",
    "        n_batches = arr.shape[axis] // batch_size\n",
    "        result = np.array_split(arr, n_batches, axis=axis)\n",
    "        i = 0\n",
    "        while result[i].shape[0] != batch_size:\n",
    "            i += 1\n",
    "        result = result[i:]\n",
    "        return result\n",
    "    \n",
    "    def _concatBatches(self, batches, axis=0):\n",
    "        return np.concatenate(batches, axis=axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_1(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (1, 58), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._flat = Flatten()(self._inputs)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._flat)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=(encoded_dim[0]*encoded_dim[1],))\n",
    "            self._flat_decoded = Dense(input_dim[0]*input_dim[1], activation=activation[1])(self._encoded_inputs)\n",
    "            self._decoded = Reshape(input_dim)(self._flat_decoded)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "            \n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (np.array(X) - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_2(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (1, 58), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._conv = Conv1D(filters=encoded_dim[1], kernel_size=kernel)(self._inputs) \n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._conv)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._decoded = Reshape(input_dim)(self._flat_decoded)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "\n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "            \n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_3(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (1, 58), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._lstm = LSTM(input_dim[1], return_sequences=True, dropout=0, recurrent_dropout=0.1)(self._inputs)\n",
    "            self._conv = Conv1D(filters=encoded_dim[1], kernel_size=input_dim[0])(self._lstm)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._conv)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "            \n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded_1 = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._flat_decoded_2 = UpSampling1D(size=input_dim[0] // encoded_dim[0])(self._flat_decoded_1)\n",
    "            self._lstm_2 = LSTM(input_dim[1], return_sequences=True)(self._flat_decoded_2)\n",
    "            self._decoded = Reshape(input_dim)(self._lstm_2)\n",
    "            \n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "            \n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "            \n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1))  + 1e-10\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_3_5(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (1, 58), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._gru = GRU(input_dim[1], return_sequences=True, dropout=0, recurrent_dropout=0.1)(self._inputs)\n",
    "            self._conv = Conv1D(filters=encoded_dim[1], kernel_size=input_dim[0])(self._gru)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._conv)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded_1 = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._flat_decoded_2 = UpSampling1D(size=input_dim[0] // encoded_dim[0])(self._flat_decoded_1)\n",
    "            self._gru_2 = GRU(input_dim[1], return_sequences=True)(self._flat_decoded_2)\n",
    "            self._decoded = Reshape(input_dim)(self._gru_2)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "\n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1)) + 1e-10\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AU_Stage_4(AutoEncoder):\n",
    "        def __init__(self, \n",
    "                 input_dim = (7, 58), \n",
    "                 encoded_dim = (1, 58), \n",
    "                 loss=\"mse\", \n",
    "                 optimizer=\"adadelta\", \n",
    "                 activation=(\"elu\", \"sigmoid\"),\n",
    "                 kernel = 7):\n",
    "        \n",
    "            self.input_dim = input_dim\n",
    "            self.encoded_dim = encoded_dim\n",
    "\n",
    "            #Encoder\n",
    "            self._inputs = Input(shape=input_dim)\n",
    "            self._lstm = LSTM(input_dim[1], return_sequences=True, dropout=0, recurrent_dropout=0.1)(self._inputs)\n",
    "            self._reshape = Reshape((-1, input_dim[1] * input_dim[0]))(self._lstm)\n",
    "            self._dense = Dense(units=np.prod(encoded_dim), activation=activation[0])(self._reshape)\n",
    "            self._encoded = Reshape(encoded_dim)(self._dense)\n",
    "\n",
    "            #Decoder\n",
    "            self._encoded_inputs = Input(shape=encoded_dim)\n",
    "            self._flat_decoded_1 = Dense(units=np.prod(input_dim), activation=activation[1])(self._encoded_inputs)\n",
    "            self._lstm_2 = LSTM(input_dim[1] * input_dim[0], return_sequences=True)(self._flat_decoded_1)\n",
    "            self._decoded = Reshape((-1, input_dim[1]))(self._lstm_2)\n",
    "\n",
    "            #Models\n",
    "            self.encoder = Model(self._inputs, self._encoded)\n",
    "            self.decoder = Model(self._encoded_inputs, self._decoded)\n",
    "            self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)))\n",
    "\n",
    "            self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "            class MinMaxScaler():\n",
    "\n",
    "                def __init__(self, minimum=None, maximum=None):\n",
    "                    self.minimum = minimum\n",
    "                    self.maximum = maximum\n",
    "\n",
    "                def fit_transform(self, X):\n",
    "                    if self.minimum is None or self.maximum is None:\n",
    "                        self.minimum = np.min(X, axis=(0, 1))\n",
    "                        self.maximum = np.max(X, axis=(0, 1)) + 1e-10\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def transform(self, X):\n",
    "                    return (X - self.minimum) / (self.maximum - self.minimum)\n",
    "\n",
    "                def reverse_transform(self, X_scl):\n",
    "                    return X_scl * (self.maximum - self.minimum) + self.minimum\n",
    "\n",
    "            self.scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epoch_numb = 50\n",
    "limit = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1188300, 7, 58)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we get data for all experiments in future\n",
    "au_1 = AU_Stage_1()\n",
    "data_set = au_1.prepare_clear_data(clear_data_path, limit=limit)\n",
    "train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "au_1.load(\"../experiment-1_batch7/model_stage_1/au\", X_train=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dense\n",
      "\n",
      "Clear data\n",
      "0.8247301200656326\n",
      "4.832945938199143e-06\n",
      "7.168427148160001e-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr = au_1._predict(test_data, au_1.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print('\\nDense')\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "au_2 = AU_Stage_2()\n",
    "# here we assume that batches are the same and use data from previous model to compare models correctly\n",
    "# data_set = au_2.prepare_clear_data(clear_data_path, limit=limit)\n",
    "# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "\n",
    "au_2.load(\"../experiment-1_batch7/model_stage_2/au\", X_train=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dense+Conv\n",
      "\n",
      "Clear data\n",
      "0.8257848227367229\n",
      "5.193955342016033e-06\n",
      "8.964024932534042e-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr = au_2._predict(test_data, au_2.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print('\\nDense+Conv')\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "831810/831810 [==============================] - 501s 602us/step - loss: 5.8822e-04\n",
      "Epoch 2/50\n",
      "831810/831810 [==============================] - 502s 604us/step - loss: 2.3527e-04\n",
      "Epoch 3/50\n",
      "831810/831810 [==============================] - 503s 605us/step - loss: 1.7283e-04\n",
      "Epoch 4/50\n",
      "831810/831810 [==============================] - 502s 604us/step - loss: 1.4425e-04\n",
      "Epoch 5/50\n",
      "831810/831810 [==============================] - 503s 605us/step - loss: 1.3224e-04\n",
      "Epoch 6/50\n",
      "831810/831810 [==============================] - 503s 605us/step - loss: 1.2477e-04\n",
      "Epoch 7/50\n",
      "831810/831810 [==============================] - 504s 606us/step - loss: 1.1903e-04\n",
      "Epoch 8/50\n",
      "831810/831810 [==============================] - 504s 606us/step - loss: 1.1630e-04\n",
      "Epoch 9/50\n",
      "831810/831810 [==============================] - 504s 606us/step - loss: 1.1483e-04\n",
      "Epoch 10/50\n",
      "831810/831810 [==============================] - 504s 606us/step - loss: 1.1375e-04\n",
      "Epoch 11/50\n",
      "831810/831810 [==============================] - 504s 605us/step - loss: 1.1271e-04\n",
      "Epoch 12/50\n",
      "831810/831810 [==============================] - 504s 606us/step - loss: 1.1158e-04\n",
      "Epoch 13/50\n",
      "831810/831810 [==============================] - 504s 606us/step - loss: 1.1005e-04\n",
      "Epoch 14/50\n",
      "831810/831810 [==============================] - 504s 606us/step - loss: 1.0833e-04\n",
      "Epoch 15/50\n",
      "831810/831810 [==============================] - 498s 599us/step - loss: 1.0662e-04\n",
      "Epoch 16/50\n",
      "831810/831810 [==============================] - 495s 595us/step - loss: 1.0488e-04\n",
      "Epoch 17/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 1.0291e-04\n",
      "Epoch 18/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 1.0090e-04\n",
      "Epoch 19/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 9.9116e-05\n",
      "Epoch 20/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 9.7575e-05\n",
      "Epoch 21/50\n",
      "831810/831810 [==============================] - 496s 597us/step - loss: 9.6338e-05\n",
      "Epoch 22/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 9.5188e-05\n",
      "Epoch 23/50\n",
      "831810/831810 [==============================] - 495s 595us/step - loss: 9.4006e-05\n",
      "Epoch 24/50\n",
      "831810/831810 [==============================] - 496s 597us/step - loss: 9.2479e-05\n",
      "Epoch 25/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 9.0957e-05\n",
      "Epoch 26/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 8.9777e-05\n",
      "Epoch 27/50\n",
      "831810/831810 [==============================] - 495s 595us/step - loss: 8.8891e-05\n",
      "Epoch 28/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 8.8195e-05\n",
      "Epoch 29/50\n",
      "831810/831810 [==============================] - 496s 597us/step - loss: 8.7518e-05\n",
      "Epoch 30/50\n",
      "831810/831810 [==============================] - 496s 597us/step - loss: 8.6944e-05\n",
      "Epoch 31/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 8.6402e-05\n",
      "Epoch 32/50\n",
      "831810/831810 [==============================] - 496s 597us/step - loss: 8.5846e-05\n",
      "Epoch 33/50\n",
      "831810/831810 [==============================] - 496s 596us/step - loss: 8.5359e-05\n",
      "Epoch 34/50\n",
      "831810/831810 [==============================] - 443s 533us/step - loss: 8.4885e-05\n",
      "Epoch 35/50\n",
      "831810/831810 [==============================] - 339s 407us/step - loss: 8.4427e-05\n",
      "Epoch 36/50\n",
      "831810/831810 [==============================] - 340s 408us/step - loss: 8.4051e-05\n",
      "Epoch 37/50\n",
      "831810/831810 [==============================] - 218s 262us/step - loss: 8.3630e-05\n",
      "Epoch 38/50\n",
      "831810/831810 [==============================] - 209s 252us/step - loss: 8.3228e-05\n",
      "Epoch 39/50\n",
      "831810/831810 [==============================] - 209s 252us/step - loss: 8.2905e-05\n",
      "Epoch 40/50\n",
      "831810/831810 [==============================] - 210s 252us/step - loss: 8.2486e-05\n",
      "Epoch 41/50\n",
      "831810/831810 [==============================] - 210s 252us/step - loss: 8.2107e-05\n",
      "Epoch 42/50\n",
      "831810/831810 [==============================] - 210s 252us/step - loss: 8.1659e-05\n",
      "Epoch 43/50\n",
      "831810/831810 [==============================] - 210s 252us/step - loss: 8.1208e-05\n",
      "Epoch 44/50\n",
      "831810/831810 [==============================] - 210s 252us/step - loss: 8.0681e-05\n",
      "Epoch 45/50\n",
      "831810/831810 [==============================] - 210s 252us/step - loss: 8.0136e-05\n",
      "Epoch 46/50\n",
      "831810/831810 [==============================] - 210s 252us/step - loss: 7.9534e-05\n",
      "Epoch 47/50\n",
      "831810/831810 [==============================] - 210s 253us/step - loss: 7.8893e-05\n",
      "Epoch 48/50\n",
      "831810/831810 [==============================] - 210s 253us/step - loss: 7.8156e-05\n",
      "Epoch 49/50\n",
      "831810/831810 [==============================] - 210s 253us/step - loss: 7.7529e-05\n",
      "Epoch 50/50\n",
      "831810/831810 [==============================] - 210s 253us/step - loss: 7.6811e-05\n"
     ]
    }
   ],
   "source": [
    "au_3 = AU_Stage_3()\n",
    "# here we assume that batches are the same and use data from previous model to compare models correctly\n",
    "# data_set = au_3.prepare_clear_data(clear_data_path, limit=limit)\n",
    "# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "\n",
    "au_3.fit(train_data, epochs=epoch_numb)\n",
    "folder = \"./model_stage_3/\"\n",
    "au_3.save(folder + \"au\")\n",
    "au_3.save(folder + \"en\")\n",
    "au_3.save(folder + \"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dense+Conv+LSTM\n",
      "\n",
      "Clear data\n",
      "0.7088568095962166\n",
      "9.072323809230355e-06\n",
      "1.2973953233257075e-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr = au_3._predict(test_data, au_3.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print(\"\\nDense+Conv+LSTM\")\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "au_3_5 = AU_Stage_3_5()\n",
    "# here we assume that batches are the same and use data from previous model to compare models correctly\n",
    "# data_set = au_3_5.prepare_clear_data(clear_data_path, limit=limit)\n",
    "# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "\n",
    "au_3_5.load(\"../experiment-1_batch7/model_stage_3_5/au\", X_train=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dense+Conv+GRU\n",
      "\n",
      "Clear data\n",
      "0.7829797791169523\n",
      "6.931606360453831e-06\n",
      "2.0235480838020267e-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr = au_3_5._predict(test_data, au_3_5.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print(\"\\nDense+Conv+GRU\")\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "831810/831810 [==============================] - 572s 688us/step - loss: 7.8191e-04\n",
      "Epoch 2/50\n",
      "831810/831810 [==============================] - 530s 637us/step - loss: 3.1442e-04\n",
      "Epoch 3/50\n",
      "831810/831810 [==============================] - 525s 631us/step - loss: 2.7627e-04\n",
      "Epoch 4/50\n",
      "831810/831810 [==============================] - 517s 622us/step - loss: 2.6624e-04\n",
      "Epoch 5/50\n",
      "831810/831810 [==============================] - 516s 621us/step - loss: 2.6080e-04\n",
      "Epoch 6/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 2.3560e-04\n",
      "Epoch 7/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 1.7652e-04\n",
      "Epoch 8/50\n",
      "831810/831810 [==============================] - 514s 619us/step - loss: 1.6668e-04\n",
      "Epoch 9/50\n",
      "831810/831810 [==============================] - 515s 619us/step - loss: 1.6344e-04\n",
      "Epoch 10/50\n",
      "831810/831810 [==============================] - 515s 619us/step - loss: 1.6121e-04\n",
      "Epoch 11/50\n",
      "831810/831810 [==============================] - 512s 616us/step - loss: 1.5849e-04\n",
      "Epoch 12/50\n",
      "831810/831810 [==============================] - 512s 616us/step - loss: 1.5158e-04\n",
      "Epoch 13/50\n",
      "831810/831810 [==============================] - 512s 616us/step - loss: 1.3526e-04\n",
      "Epoch 14/50\n",
      "831810/831810 [==============================] - 512s 615us/step - loss: 1.2453e-04\n",
      "Epoch 15/50\n",
      "831810/831810 [==============================] - 513s 616us/step - loss: 1.2029e-04\n",
      "Epoch 16/50\n",
      "831810/831810 [==============================] - 513s 617us/step - loss: 1.1817e-04\n",
      "Epoch 17/50\n",
      "831810/831810 [==============================] - 513s 617us/step - loss: 1.1653e-04\n",
      "Epoch 18/50\n",
      "831810/831810 [==============================] - 513s 617us/step - loss: 1.1469e-04\n",
      "Epoch 19/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 1.1192e-04\n",
      "Epoch 20/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 1.0800e-04\n",
      "Epoch 21/50\n",
      "831810/831810 [==============================] - 513s 617us/step - loss: 1.0459e-04\n",
      "Epoch 22/50\n",
      "831810/831810 [==============================] - 512s 615us/step - loss: 1.0237e-04\n",
      "Epoch 23/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 1.0087e-04\n",
      "Epoch 24/50\n",
      "831810/831810 [==============================] - 519s 624us/step - loss: 9.9755e-05\n",
      "Epoch 25/50\n",
      "831810/831810 [==============================] - 515s 619us/step - loss: 9.8842e-05\n",
      "Epoch 26/50\n",
      "831810/831810 [==============================] - 512s 616us/step - loss: 9.8084e-05\n",
      "Epoch 27/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 9.7388e-05\n",
      "Epoch 28/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 9.6753e-05\n",
      "Epoch 29/50\n",
      "831810/831810 [==============================] - 513s 617us/step - loss: 9.6108e-05\n",
      "Epoch 30/50\n",
      "831810/831810 [==============================] - 513s 616us/step - loss: 9.5464e-05\n",
      "Epoch 31/50\n",
      "831810/831810 [==============================] - 515s 619us/step - loss: 9.4756e-05\n",
      "Epoch 32/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 9.3983e-05\n",
      "Epoch 33/50\n",
      "831810/831810 [==============================] - 514s 617us/step - loss: 9.3095e-05\n",
      "Epoch 34/50\n",
      "831810/831810 [==============================] - 513s 617us/step - loss: 9.2066e-05\n",
      "Epoch 35/50\n",
      "831810/831810 [==============================] - 513s 617us/step - loss: 9.0875e-05\n",
      "Epoch 36/50\n",
      "831810/831810 [==============================] - 514s 618us/step - loss: 8.9562e-05\n",
      "Epoch 37/50\n",
      "831810/831810 [==============================] - 516s 620us/step - loss: 8.8100e-05\n",
      "Epoch 38/50\n",
      "831810/831810 [==============================] - 515s 620us/step - loss: 8.6596e-05\n",
      "Epoch 39/50\n",
      "831810/831810 [==============================] - 516s 620us/step - loss: 8.5036e-05\n",
      "Epoch 40/50\n",
      "831810/831810 [==============================] - 515s 619us/step - loss: 8.3459e-05\n",
      "Epoch 41/50\n",
      "831810/831810 [==============================] - 517s 622us/step - loss: 8.1922e-05\n",
      "Epoch 42/50\n",
      "831810/831810 [==============================] - 517s 622us/step - loss: 8.0484e-05\n",
      "Epoch 43/50\n",
      "831810/831810 [==============================] - 517s 621us/step - loss: 7.9201e-05\n",
      "Epoch 44/50\n",
      "831810/831810 [==============================] - 517s 622us/step - loss: 7.8049e-05\n",
      "Epoch 45/50\n",
      "831810/831810 [==============================] - 518s 622us/step - loss: 7.6944e-05\n",
      "Epoch 46/50\n",
      "831810/831810 [==============================] - 517s 622us/step - loss: 7.5838e-05\n",
      "Epoch 47/50\n",
      "831810/831810 [==============================] - 517s 621us/step - loss: 7.4684e-05\n",
      "Epoch 48/50\n",
      "831810/831810 [==============================] - 518s 622us/step - loss: 7.3441e-05\n",
      "Epoch 49/50\n",
      "831810/831810 [==============================] - 517s 622us/step - loss: 7.2127e-05\n",
      "Epoch 50/50\n",
      "831810/831810 [==============================] - 517s 622us/step - loss: 7.0786e-05\n"
     ]
    }
   ],
   "source": [
    "au_4 = AU_Stage_4()\n",
    "# here we assume that batches are the same and use data from previous model to compare models correctly\n",
    "# data_set = au_4.prepare_clear_data(clear_data_path, limit=limit)\n",
    "# train_data, test_data = train_test_split(data_set, random_state=0, test_size=0.3)\n",
    "\n",
    "au_4.fit(train_data, epochs=epoch_numb)\n",
    "folder = \"./model_stage_4/\"\n",
    "au_4.save(folder + \"au\")\n",
    "au_4.save(folder + \"en\")\n",
    "au_4.save(folder + \"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dense+LSTM\n",
      "\n",
      "Clear data\n",
      "0.762404942330928\n",
      "5.4105242149271395e-06\n",
      "1.0132845665360928e-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr = au_4._predict(test_data, au_4.autoencoder)\n",
    "ds = np.concatenate(test_data)\n",
    "p = np.concatenate(pr)\n",
    "print(\"\\nDense+LSTM\")\n",
    "print('\\nClear data')\n",
    "print(r2_score(ds, p))\n",
    "print(mean_absolute_error(ds, p))\n",
    "print(mean_squared_error(ds, p))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del au_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
